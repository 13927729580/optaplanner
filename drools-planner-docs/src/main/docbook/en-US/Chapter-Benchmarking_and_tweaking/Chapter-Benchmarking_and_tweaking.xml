<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0"
         xsi:schemaLocation="http://docbook.org/ns/docbook http://www.docbook.org/xml/5.0/xsd/docbook.xsd http://www.w3.org/1999/xlink http://www.docbook.org/xml/5.0/xsd/xlink.xsd"
         xml:base="../" xmlns="http://docbook.org/ns/docbook" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:ns="http://docbook.org/ns/docbook">
  <title>Benchmarking and tweaking</title>

  <section>
    <title>Finding the best configuration</title>

    <para>Drools Planner supports several optimization algorithms (as solver phases), but you're probably wondering
    which is the best one? Although some optimization algorithms generally perform better then others, it really depends
    on your problem domain. Most solver phases have settings which can be tweaked. Those settings can influence the
    results a lot, although most solver phases work pretty well out-of-the-box.</para>

    <para>Luckily, Drools Planner includes a benchmarker, which allows you to play out different solver phases with
    different settings against each other, so you can pick the best configuration for your planning problem.</para>
  </section>

  <section>
    <title>Building a benchmarker</title>

    <section>
      <title>Adding the extra dependency</title>

      <para>The benchmarker is current in the drools-planner-core modules, but it requires an extra dependency on the
      <link xlink:href="http://www.jfree.org/jfreechart/">JFreeChart</link> library.</para>

      <para>If you use maven, add a dependency in your <filename>pom.xml</filename> file:</para>

      <programlisting language="xml">    &lt;dependency&gt;
      &lt;groupId&gt;jfree&lt;/groupId&gt;
      &lt;artifactId&gt;jfreechart&lt;/artifactId&gt;
      &lt;version&gt;1.0.13&lt;/version&gt;
    &lt;/dependency&gt;</programlisting>

      <para>This is similar for gradle, ivy and buildr.</para>

      <para>If you use ANT, you've probably already copied the required jars from the download zip's
      <filename>binaries</filename> directory.</para>
    </section>

    <section>
      <title>Building a <literal>PlannerBenchmark</literal></title>

      <para>You can build a <literal>PlannerBenchmark</literal> instance with the <literal>XmlPlannerBenchmarkFactory</literal>.
      Configure it with a benchmark configuration xml file:</para>

      <programlisting language="java">    XmlPlannerBenchmarkFactory plannerBenchmarkFactory = new XmlPlannerBenchmarkFactory();
    plannerBenchmarkFactory.configure("/org/drools/planner/examples/nqueens/benchmark/nqueensBenchmarkConfig.xml");
    PlannerBenchmark plannerBenchmark = benchmarkFactory.buildPlannerBenchmark();
    plannerBenchmark.benchmark();</programlisting>

      <para>A basic benchmark configuration file looks something like this:</para>

      <programlisting language="xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;plannerBenchmark&gt;
  &lt;benchmarkDirectory&gt;local/data/nqueens&lt;/benchmarkDirectory&gt;
  &lt;warmUpSecondsSpend&gt;30&lt;/warmUpSecondsSpend&gt;

  &lt;inheritedSolverBenchmark&gt;
    &lt;problemBenchmarks&gt;
      &lt;xstreamAnnotatedClass&gt;org.drools.planner.examples.nqueens.domain.NQueens&lt;/xstreamAnnotatedClass&gt;
      &lt;inputSolutionFile&gt;data/nqueens/unsolved/unsolvedNQueens32.xml&lt;/inputSolutionFile&gt;
      &lt;inputSolutionFile&gt;data/nqueens/unsolved/unsolvedNQueens64.xml&lt;/inputSolutionFile&gt;
      &lt;problemStatisticType&gt;BEST_SOLUTION_CHANGED&lt;/problemStatisticType&gt;
    &lt;/problemBenchmarks&gt;
    &lt;solver&gt;
      &lt;solutionClass&gt;org.drools.planner.examples.nqueens.domain.NQueens&lt;/solutionClass&gt;
      &lt;planningEntityClass&gt;org.drools.planner.examples.nqueens.domain.Queen&lt;/planningEntityClass&gt;
      &lt;scoreDrl&gt;/org/drools/planner/examples/nqueens/solver/nQueensScoreRules.drl&lt;/scoreDrl&gt;
      &lt;scoreDefinition&gt;
        &lt;scoreDefinitionType&gt;SIMPLE&lt;/scoreDefinitionType&gt;
      &lt;/scoreDefinition&gt;
      &lt;termination&gt;
        &lt;maximumSecondsSpend&gt;20&lt;/maximumSecondsSpend&gt;
      &lt;/termination&gt;
      &lt;constructionHeuristic&gt;
        &lt;constructionHeuristicType&gt;FIRST_FIT_DECREASING&lt;/constructionHeuristicType&gt;
        &lt;constructionHeuristicPickEarlyType&gt;FIRST_LAST_STEP_SCORE_EQUAL_OR_IMPROVING&lt;/constructionHeuristicPickEarlyType&gt;
      &lt;/constructionHeuristic&gt;
    &lt;/solver&gt;
  &lt;/inheritedSolverBenchmark&gt;

  &lt;solverBenchmark&gt;
    &lt;name&gt;Solution tabu&lt;/name&gt;
    &lt;solver&gt;
      &lt;localSearch&gt;
        &lt;selector&gt;
          &lt;moveFactoryClass&gt;org.drools.planner.examples.nqueens.solver.move.factory.RowChangeMoveFactory&lt;/moveFactoryClass&gt;
        &lt;/selector&gt;
        &lt;acceptor&gt;
          &lt;solutionTabuSize&gt;1000&lt;/solutionTabuSize&gt;
        &lt;/acceptor&gt;
        &lt;forager&gt;
          &lt;pickEarlyType&gt;NEVER&lt;/pickEarlyType&gt;
        &lt;/forager&gt;
      &lt;/localSearch&gt;
    &lt;/solver&gt;
  &lt;/solverBenchmark&gt;
  &lt;solverBenchmark&gt;
    &lt;name&gt;Move tabu&lt;/name&gt;
    &lt;solver&gt;
      &lt;localSearch&gt;
        &lt;selector&gt;
          &lt;moveFactoryClass&gt;org.drools.planner.examples.nqueens.solver.move.factory.RowChangeMoveFactory&lt;/moveFactoryClass&gt;
        &lt;/selector&gt;
        &lt;acceptor&gt;
          &lt;moveTabuSize&gt;5&lt;/moveTabuSize&gt;
        &lt;/acceptor&gt;
        &lt;forager&gt;
          &lt;pickEarlyType&gt;NEVER&lt;/pickEarlyType&gt;
        &lt;/forager&gt;
      &lt;/localSearch&gt;
    &lt;/solver&gt;
  &lt;/solverBenchmark&gt;
  &lt;solverBenchmark&gt;
    &lt;name&gt;Property tabu&lt;/name&gt;
    &lt;solver&gt;
      &lt;localSearch&gt;
        &lt;selector&gt;
          &lt;moveFactoryClass&gt;org.drools.planner.examples.nqueens.solver.move.factory.RowChangeMoveFactory&lt;/moveFactoryClass&gt;
        &lt;/selector&gt;
        &lt;acceptor&gt;
          &lt;propertyTabuSize&gt;5&lt;/propertyTabuSize&gt;
        &lt;/acceptor&gt;
        &lt;forager&gt;
          &lt;pickEarlyType&gt;NEVER&lt;/pickEarlyType&gt;
        &lt;/forager&gt;
      &lt;/localSearch&gt;
    &lt;/solver&gt;
  &lt;/solverBenchmark&gt;
&lt;/plannerBenchmark&gt;</programlisting>

      <para>This <literal>PlannerBenchmark</literal> will try 3 configurations (1 solution tabu, 1 move tabu and 1 property tabu) on 2 data sets
      (32 and 64 queens), so it will run 6 solvers.</para>

      <para>Every <literal>solverBenchmark</literal> entity contains a solver configuration (for example with a local
      search solver phase) and one or more <literal>inputSolutionFile</literal> elements. It will run the solver
      configuration on each of those unsolved solution files. A <literal>name</literal> is optional and generated if
      absent.</para>

      <para>The common part of multiple <literal>solverBenchmark</literal> entities can be extracted to the
      <literal>inheritedSolverBenchmark</literal> entity, but that can still be overwritten per
      <literal>solverBenchmark</literal> entity. Note that inherited solver phases such as
      <literal>&lt;constructionHeuristic&gt;</literal> or <literal>&lt;localSearch&gt;</literal> are not overwritten but
      instead are added to the head of the solver phases list.</para>

      <para>You need to specify a <literal>benchmarkDirectory</literal> (relative to the working directory). The best
      solution of each <literal>Solver</literal> run and a handy overview HTML file will be written in that
      directory.</para>
    </section>

    <section>
      <title>ProblemIO: input and output of Solution files</title>

      <section>
        <title><literal>ProblemIO</literal> interface</title>

        <para>The benchmarker needs to be able to read the input files to contain a <literal>Solution</literal> write
        the best <literal>Solution</literal> of each benchmark to an output file. For that it uses a class that
        implements the <literal>ProblemIO</literal> interface:</para>

        <programlisting language="java">public interface ProblemIO {

    String getFileExtension();

    Solution read(File inputSolutionFile);

    void write(Solution solution, File outputSolutionFile);

}</programlisting>
      </section>

      <section>
        <title><literal>XStreamProblemIO</literal></title>

        <para>By default, a <literal>XStreamProblemIO</literal> instance is used and you just need to configure your
        <literal>Solution</literal> class as being annotated with XStream:</para>

        <programlisting language="xml">    &lt;problemBenchmarks&gt;
      &lt;xstreamAnnotatedClass&gt;org.drools.planner.examples.nqueens.domain.NQueens&lt;/xstreamAnnotatedClass&gt;
      &lt;inputSolutionFile&gt;data/nqueens/unsolved/unsolvedNQueens32.xml&lt;/inputSolutionFile&gt;
      ...
    &lt;/problemBenchmarks&gt;</programlisting>

        <para>However, your input files need to have been written with a <literal>XStreamProblemIO</literal> instance.
        </para>
      </section>

      <section>
        <title>Custom <literal>ProblemIO</literal></title>

        <para>Alternatively, you can implement your own <literal>ProblemIO</literal> implementation and configure it
        with the <literal>problemIOClass</literal> element:</para>

        <programlisting language="xml">    &lt;problemBenchmarks&gt;
      &lt;problemIOClass&gt;org.drools.planner.examples.machinereassignment.persistence.MachineReassignmentProblemIO&lt;/problemIOClass&gt;
      &lt;inputSolutionFile&gt;data/machinereassignment/input/model_a1_1.txt&lt;/inputSolutionFile&gt;
      ...
    &lt;/problemBenchmarks&gt;</programlisting>
      </section>
    </section>

    <section>
      <title>Warming up the hotspot compiler</title>

      <para>Without a warm up, the results of the first (or first few) benchmarks are not reliable, because they will
      have lost CPU time on hotspot JIT compilation (and possibly DRL compilation too).</para>

      <para>The avoid that distortion, the benchmarker can run some of the benchmarks for a specified amount of time,
      before running the real benchmarks. Generally, a warm up of 30 seconds suffices:</para>

      <programlisting language="xml">&lt;plannerBenchmark&gt;
  ...
  &lt;warmUpSecondsSpend&gt;30&lt;/warmUpSecondsSpend&gt;
  ...
&lt;/plannerBenchmark&gt;</programlisting>
    </section>
  </section>

  <section>
    <title>Summary statistics</title>

    <section>
      <title>Best score summary</title>

      <para>Several summary statistics of the <literal>PlannerBenchmark</literal> run will be written in the
      <literal>benchmarkDirectory</literal>. Here is an example of a summary statistic:</para>

      <figure>
        <title>Best score summary statistic</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Chapter-Benchmarking_and_tweaking/summaryStatistic.png" format="PNG"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>
    </section>
  </section>

  <section>
    <title>Statistics per data set (graph and CSV)</title>

    <para>The benchmarker supports outputting statistics as graphs and CSV (comma separated values) files to the
    <literal>benchmarkDirectory</literal>.</para>

    <para>To configure graph and CSV output of a statistic, just add a <literal>problemStatisticType</literal>
    line:</para>

    <programlisting language="xml">&lt;plannerBenchmark&gt;
  &lt;benchmarkDirectory&gt;local/data/nqueens/solved&lt;/benchmarkDirectory&gt;
  &lt;inheritedSolverBenchmark&gt;
    &lt;problemBenchmarks&gt;
      ...
      &lt;problemStatisticType&gt;BEST_SOLUTION_CHANGED&lt;/problemStatisticType&gt;
      &lt;problemStatisticType&gt;CALCULATE_COUNT_PER_SECOND&lt;/problemStatisticType&gt;
    &lt;/problemBenchmarks&gt;
    ...
  &lt;/inheritedSolverBenchmark&gt;
  ...
&lt;/plannerBenchmark&gt;</programlisting>

    <para>Multiple <literal>problemStatisticType</literal> elements are allowed. Some statistic types might influence
    performance noticeably. The following types are supported:</para>

    <section>
      <title>Best score over time statistic (graph and CSV)</title>

      <para>To see how the best score evolves over time, add <literal>BEST_SOLUTION_CHANGED</literal> as <literal>a
      problemStatisticType</literal>.</para>

      <figure>
        <title>Best score over time statistic</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Chapter-Benchmarking_and_tweaking/bestSolutionChangedStatistic.png" format="PNG"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>

      <para><emphasis role="bold">The best score over time statistic is very useful to detect abnormalities, such as
      score traps.</emphasis></para>

      <note>
        <para>Don't be fooled by the simulated annealing line in this graph. If you give simulated annealing only 5
        minutes, it might still be better than 5 minutes of tabu search. That's because this simulated annealing
        implementation automatically determines its velocity based on the amount of time that can be spend. On the
        other hand, for the tabu search, what you see is what you'd get.</para>
      </note>
    </section>

    <section>
      <title>Calculate count per second statistic (graph and CSV)</title>

      <para>To see how fast the scores are calculated, add <literal>CALCULATE_COUNT_PER_SECOND</literal> as a
      <literal>problemStatisticType</literal>.</para>

      <figure>
        <title>Calculate count per second statistic</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Chapter-Benchmarking_and_tweaking/calculateCountPerSecondStatistic.png"
                       format="PNG"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>

      <note>
        <para>The initial high calculate count is typical during solution initialization. In this example, it's far
        easier to calculate the score of a solution if only a handful exams have been added, in contrast to all of them.
        After those few seconds of initialization, the calculate count is relatively stable, apart from an occasional
        stop-the-world garbage collector disruption.</para>
      </note>
    </section>

    <section>
      <title>Memory use statistic (graph and CSV)</title>

      <para>To see how much memory is used, add <literal>MEMORY_USE</literal> as <literal>a
      problemStatisticType</literal>.</para>

      <figure>
        <title>Memory use statistic</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Chapter-Benchmarking_and_tweaking/memoryUseStatistic.png" format="PNG"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>
    </section>
  </section>
</chapter>
